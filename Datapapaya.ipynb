{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Datapapaya.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM/OXR7JqeNwPWkk7Ub90HT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earth1429/AI-ClassifyImage/blob/main/Datapapaya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbL7DlUmfmGR"
      },
      "source": [
        "# Importing all necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7z8iAmlGMT9",
        "outputId": "ef695fc3-e133-46d3-fff5-8bfe51009760"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMPzKaxTpSxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "829fb7df-09c8-4f11-b102-f755e43a8e26"
      },
      "source": [
        "# #Dome\n",
        "# train_datagenerator = ImageDataGenerator(rescale=1./255)\n",
        "# test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# train_datagenerator = train_datagenerator.flow_from_directory(\n",
        "#     '/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Train',\n",
        "#     target_size=(128,128),\n",
        "#     batch_size=32,\n",
        "#     class_mode='binary')\n",
        "\n",
        "# test_datagenerator = test_datagenerator.flow_from_directory(\n",
        "#     '/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Test',\n",
        "#     target_size=(128,128),\n",
        "#     batch_size=32,\n",
        "#     class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 525 images belonging to 3 classes.\n",
            "Found 91 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r7qZ7_vZWFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da49e81-778d-4157-efd1-a91958113acd"
      },
      "source": [
        "#Toei\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale = 1. / 255, \n",
        "    shear_range = 0.2, \n",
        "    zoom_range = 0.2, \n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    rotation_range = 180,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    validation_split = 0.2) \n",
        "\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Train', \n",
        "    target_size =(128, 128),\n",
        "    batch_size=32,\n",
        "    shuffle = True,\n",
        "    class_mode = 'sparse',\n",
        "    seed = 42,\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = data_generator.flow_from_directory( \n",
        "    '/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Train', \n",
        "    target_size =(128, 128),\n",
        "    batch_size=32,\n",
        "    shuffle = True,\n",
        "    class_mode = 'sparse',\n",
        "    seed = 42,\n",
        "    subset='validation')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 373 images belonging to 3 classes.\n",
            "Found 93 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX2DTfgwlSYL"
      },
      "source": [
        "# Use the Image Data generator to import the images from the dataset\n",
        "\n",
        "# X_train = []\n",
        "# Y_train = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVUQ9yEKxTVG"
      },
      "source": [
        "#medium\n",
        "# for filename in os.listdir('/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Train/Medium'):\n",
        "#   f = os.path.join('/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Train/Medium', filename)\n",
        "#   img = cv2.imread(f)\n",
        "#   img = cv2.resize(img,(128,128))\n",
        "#   img = img / 255.\n",
        "#   img = img.reshape(128,128,3)\n",
        "#   X_train.append(img)\n",
        "#   Y_train.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYM3C03zzJl9"
      },
      "source": [
        "#ripe\n",
        "# for filename in os.listdir('/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Train/Ripe'):\n",
        "#   f = os.path.join('/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Train/Ripe', filename)\n",
        "#   img = cv2.imread(f)\n",
        "#   img = cv2.resize(img,(128,128))\n",
        "#   img = img / 255.\n",
        "#   img = img.reshape(128,128,3)\n",
        "#   X_train.append(img)\n",
        "#   Y_train.append(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vGi-raRzJdm"
      },
      "source": [
        "#unripe\n",
        "# for filename in os.listdir('/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Train/Unripe'):\n",
        "#   f = os.path.join('/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Train/Unripe', filename)\n",
        "#   img = cv2.imread(f)\n",
        "#   img = cv2.resize(img,(128,128))\n",
        "#   img = img / 255.\n",
        "#   img = img.reshape(128,128,3)\n",
        "#   X_train.append(img)\n",
        "#   Y_train.append(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO97WWYamZ6s"
      },
      "source": [
        "#Dome\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "  tf.keras.layers.Conv2D(16, (3,3),padding='same', activation='relu', input_shape=(128,128, 3)),\n",
        "  tf.keras.layers.MaxPooling2D((2,2),2), \n",
        "  \n",
        "  # tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "  # tf.keras.layers.MaxPooling2D((2,2),2),\n",
        "\n",
        "  tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D((2,2),2), \n",
        "\n",
        "  # tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "  # tf.keras.layers.MaxPooling2D((2,2),2),\n",
        "\n",
        "  # tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "  # tf.keras.layers.MaxPooling2D((2,2),2),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "\n",
        "  tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ptuxtkyubps"
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOEqSLyvPC6-",
        "outputId": "79bf608a-272f-4f04-ef78-11e8abfd6a42"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_94 (Conv2D)           (None, 128, 128, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_94 (MaxPooling (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 64, 64, 64)        9280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_95 (MaxPooling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_32 (Flatten)         (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 64)                4194368   \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 4,204,291\n",
            "Trainable params: 4,204,291\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Jcz6rmu-Ft"
      },
      "source": [
        "# X_train = np.array(X_train)\n",
        "# Y_train = np.array(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "652oCankqDxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa223881-7d92-4d96-aeef-c0a06b0206c9"
      },
      "source": [
        "model.fit(train_generator, epochs=10, validation_data=validation_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.5809 - accuracy: 0.5013 - val_loss: 0.6848 - val_accuracy: 0.8065\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 14s 1s/step - loss: 0.4464 - accuracy: 0.8740 - val_loss: 0.1986 - val_accuracy: 0.8925\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 14s 1s/step - loss: 0.1526 - accuracy: 0.9491 - val_loss: 0.0611 - val_accuracy: 0.9677\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 14s 1s/step - loss: 0.1539 - accuracy: 0.9437 - val_loss: 0.1841 - val_accuracy: 0.9355\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 14s 1s/step - loss: 0.0938 - accuracy: 0.9571 - val_loss: 0.0395 - val_accuracy: 0.9892\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 14s 1s/step - loss: 0.1278 - accuracy: 0.9625 - val_loss: 0.1409 - val_accuracy: 0.9140\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 14s 1s/step - loss: 0.1610 - accuracy: 0.9276 - val_loss: 0.0322 - val_accuracy: 0.9892\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 14s 1s/step - loss: 0.0714 - accuracy: 0.9759 - val_loss: 0.0553 - val_accuracy: 0.9570\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 14s 1s/step - loss: 0.0945 - accuracy: 0.9759 - val_loss: 0.0395 - val_accuracy: 0.9785\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 14s 1s/step - loss: 0.1095 - accuracy: 0.9544 - val_loss: 0.1007 - val_accuracy: 0.9785\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb59685f190>"
            ]
          },
          "metadata": {},
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2Dc10o9044e"
      },
      "source": [
        "# model.fit(X_train,Y_train, epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7rswvy2Z80x"
      },
      "source": [
        "#Toei\n",
        "filePath = '/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAdP2DU5KyFR"
      },
      "source": [
        "#Toei\n",
        "# Save Model\n",
        "model.save(filePath+'Model/New2papaya.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_sIMTwuYrY"
      },
      "source": [
        "model = tf.keras.models.load_model(filePath+'Model/New2papaya.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRK2EOpy0Q7Q"
      },
      "source": [
        "# #Dome\n",
        "# model = tf.keras.models.load_model('DomePapaya.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WMCtO5o0DsI"
      },
      "source": [
        "# #Dome\n",
        "# path = '/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Test/Ripe/ripe_001.PNG'\n",
        "# img = image.load_img(path, target_size=(128, 128, 3))\n",
        "# x = image.img_to_array(img)\n",
        "# x = np.expand_dims(x, axis=0)\n",
        "\n",
        "# images = np.vstack([x])\n",
        "# classes = model.predict(images)\n",
        "# print(classes[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9T7A6NLPDQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfbc84f-57b2-4f61-8d98-31919d3a33f8"
      },
      "source": [
        "path = filePath+'Predict/papaya_023.PNG'\n",
        "img = image.load_img(path, target_size=(128, 128, 3))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images)\n",
        "\n",
        "print(classes[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApHRawCCPDAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15cc166-0777-4cfd-9af4-1dc2ce51fed5"
      },
      "source": [
        "status = np.argmax(classes[0])\n",
        "\n",
        "def translate(x):\n",
        "    return {\n",
        "        0: 'ripe',\n",
        "        1: 'medium',\n",
        "        2: 'unripe',\n",
        "        3: 'error'\n",
        "    }.get(x, 3)\n",
        "\n",
        "print(translate(status))\n",
        "print(classes[0, status])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medium\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3zteaOEssQ_"
      },
      "source": [
        "# from keras.models import load_model\n",
        "# def classify_img(filename):\n",
        "#   result=[]\n",
        "#   Loadmodel = load_model('/content/OtherPapaya101.h5')\n",
        "#   img = cv2.imread(filename)\n",
        "#   cv2_imshow(img)\n",
        "  \n",
        "#   img = cv2.resize(img,(128,128))\n",
        "#   img = img /255.\n",
        "#   img = img.reshape(128,128,3)\n",
        "#   result.append(img)\n",
        "#   result = np.array(result)\n",
        "\n",
        "#   final = model.predict(result)\n",
        "#   np.array(final)\n",
        "#   if (np.argmax(final)==1):\n",
        "#     return \"It's medium\"\n",
        "#   elif (np.argmax(final)==2):\n",
        "#     return \"It's ripe\"\n",
        "#   else:\n",
        "#     return \"It's unripe\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25TNaC1a58sY"
      },
      "source": [
        "# classify_img('/content/drive/MyDrive/ปี 3 เทอม 1/CSC340 AI/DataTraining/Test/Unripe/unripe_013.PNG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kXfIeY5bGvC"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "x_predict = []\n",
        "for filename in os.listdir(filePath+'Predict'):\n",
        "  f = os.path.join(filePath+'Predict', filename)\n",
        "  img = image.load_img(f, target_size=(128, 128, 3))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  # img = cv2.imread(f)\n",
        "  # img = image.img_to_array(img)\n",
        "  # img = cv2.resize(img,(128,128))\n",
        "  # img = img / 255.\n",
        "  # img = img.reshape(128,128,3)\n",
        "  # img = np.expand_dims(img, axis=0)\n",
        "  classes = model.predict(images)\n",
        "  x_predict.append(translate(np.argmax(classes[0])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ahDibK4ZEFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c00004-8338-4130-b8e2-36e989d12a5a"
      },
      "source": [
        "x_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['medium',\n",
              " 'medium',\n",
              " 'ripe',\n",
              " 'unripe',\n",
              " 'unripe',\n",
              " 'unripe',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'unripe',\n",
              " 'ripe',\n",
              " 'unripe',\n",
              " 'unripe',\n",
              " 'unripe',\n",
              " 'unripe',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'unripe',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'medium',\n",
              " 'unripe',\n",
              " 'medium']"
            ]
          },
          "metadata": {},
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26GXSVmcHlYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff3aa34-e967-4b10-d983-fb5f8d10d6f3"
      },
      "source": [
        "# Confusion matrix\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "\n",
        "x_actual = pd.read_csv(filePath+'Model/PapayaResult.csv', header = None)\n",
        "print(metrics.confusion_matrix(x_actual, x_predict, labels=['ripe', 'medium', 'unripe']))\n",
        "print(metrics.classification_report(x_actual, x_predict, labels=['ripe', 'medium', 'unripe']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 7 2]\n",
            " [1 6 3]\n",
            " [0 5 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ripe       0.50      0.10      0.17        10\n",
            "      medium       0.33      0.60      0.43        10\n",
            "      unripe       0.50      0.50      0.50        10\n",
            "\n",
            "    accuracy                           0.40        30\n",
            "   macro avg       0.44      0.40      0.37        30\n",
            "weighted avg       0.44      0.40      0.37        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}